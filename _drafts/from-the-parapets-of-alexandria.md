---
title: "From the Parapets of Alexandria: Knowledge Extinction Events"
categories: "blog"
tags: "sociology politics epistemology censorship"
headline: ""
author:
  name: "David Conner"
excerpt: ""
---

#### see Genius (documentary about Thomas Wolfe)

"Social Media Ghettos"

================================================================

# Part Two: Philosophy of Censorship

- in order to explore to really explore the ethics of censorship
  - i need to discuss the *factions* invested for/against
  - then elaborate on the *motivating factors*
- there are many reasons why people would want to restrict information
  - but it's hard to weigh the pros/cons here, without understanding
    who might want to restrict/widen access to information and why

# Dimensions to Consider in the Technology and Censorship Debate

### Peak Tyranny
### Stifled Development

# Intro

### Ethical Questions

- pose some basic ethical questions on 21st century censorship

# Factions Invested For/Against Censorship

### Corporations and Multinational Conglomerates

### National Security

### Political Parties

### Political Movements

### Political Movements

### Military Organizations

### Individuals

### Academic Institutions

### The People

### (some groups of people might be locked out

# Motivations For/Against Censorship

### ....

# Censorship's effect on Cultural Development

### Thermopylae

### Hip Hop

### BLM

### Censorship on Expression

# What is "The Prophecy"

- move this to its own article/series?

### Networks w/o Limitation

### Ideas Acquire Life of Their Own

### A Reevaluation of Life, ...

### Our Rights are Sacred

### Control of Information & 21st Century Economics

### SIGINT/.../...



================================================================

#### Part Three(?): Philosophy of Censorship

- why free exchange of ideas matters!
  - why is it that free exchange of ideas leads to progress for
    humanity
  - why and exactly how does limiting the free exchange of knowedge,
    information and ideas lead to limiting progress of humanities &
    philosophy
    - especially from an epistemological standpoint

================================================================

#### Part Four(?): Censorship In Social Media (title?)

intro:

America and the industrialized world now communicate almost completely
using digitized media. Text messages, emails, VOIP, video: each are
digital, each carries metadata that can be collected and datamined.
This changes the nature of communication. It means that, if
effectively all socialization occurs over digitized media and with
common digitized protocols, then any party who controls that shared
fabric of communication has immense power. They can change what you
see by affecting the bahavior of newsfeed and clustering
algorithms. They can prevent others from seeing your messages by
intercepting them or muting the notifications. If they're textual
messages how would you or the other party become aware? They can
deploy exploits like this only when it's safe to assume you wouldn't
communicate about it: like when your GPS signals aren't in the same
location. And if they simply mute the notification -- oops it must be
a bug or something.

================================================================

### [Social Media Censorship]()

What makes it OK to passively aggressively shadowban someone through
manipulation of search and newsfeed algorithms? When tech companies
are using automated algorithms to prevent others from seeing it
they're doing in a passive aggressive manner that *seeks to waste this
person's time and energy* in such a way that's difficult to counter,
it seems this is counterproductive and leads to a poor investment of
labor, time, and energy when observed at a larger scale.

BUT THAT'S THE POINT, ISN'T IT? To disempower people passionate about
specific topics that are censored and delisted on Twitter and
Facebook! And... (what?)

================================================================

The real value in social media is user time and attention. Some social
media products engage millions or billions of user-hours of per
day. Control over whether and how information is presented is
incredibly powerful! It's subject to sufficient influence by
corporations or governments, yet the effects these entities have on
these industries is erratic and unpredictable.

Without external manipulation, newsfeed and search algorithms are
difficult to implement redundantly, efficiently, and equitably. These
SEO providers are in an arms race with the algorithms of Search and
Social giants. There are entire industries dedicated to SEO and social
media to fairly influence these algorithms and their products are
layered on top of products like Facebook and Google. When the
government pressures Twitter to remove trends, they may be nullifying
the influence of hundreds of thousands of passionate grassroots
protesters who managed to land their first major trend after months of
hard work. A government or corporation who exerts significant
influence over the information presented in Facebook News or Twitter
trends may be muzzling a viral publicity success only achieved through
millions of dollars in donations to a non-profit.

In pursuit of controlling these new, decentralized mediums, these
large, powerful entities are strong arming the economics of the social
media industry. This not only robs people of their voice and
influence, but also degrades several key metrics in the technology
space: actual delivered value to customers (impressions, clicks,
conversions, engagement time), expectation of ROI for consumers,
quality of service to customers, customer satisfaction, and the fair
market price for a product.

Since social media consumers only have a limited amount of time per
day, this is analagous to a house party that orders a large amount of
pizza, which represents the purchase of SEO services or advertising
from Twitter. As the total time of user engagement is fairly fixed,
there is only so much pizza to go around at that party: what the
attendees ordered. But government interference in social media is like
a group of drunk people showing up to your party and taking away
entire pizzas. It completely interferes with the economics of tech
products by indirectly and directly affecting the metrics mentioned
above. This should violate policy with the FCC for interfering with
the authenticity of message and delivery of content. Similarly, this
should violate some federal policy for mucking around in specific
industries, though it's outside the SEC's purview.

This is a clear example of how Big Government's overreach interferes
with the equitable, transparent and efficient functioning of a market,
bogging it down and making it less competitive to global markets!

- comments on bureaucracy, lack of oversight in pursuit of policy
  implementation by bureaucracies, with regard to social media
  - lack of accountability for social media budgets
    - things change so quickly that, except for long term campaigns,
      it becomes difficult to track how money is spent for social
      media advertising and optimization.
      - i'm sure this problem has been experienced to some degree with
        advertising fund invested in traditional media. however,
        traditional media has a longer feedback loop b/w planning,
        purchase and execution. the shorter feedback loop could leave
        less time for planning & decision making.
      - this problem might only pop up in government/corporate
        entities with large social media budgets


The attendees decided to pitch...

There are several arguments for restricting government interference in
the operation of web applications.

Passive surveillance of data isn't as worrying as direct influence of
their products. In the US, the telecom industry is tightly coupled to
the federal government. Control of telecom industry, the fabric of the
route/switch layer, and access/documentation for the physical layer
confers God-like hacking powers. Access or influence to any of these
things makes otherwise challenging hacks absolutely trivial.

However, strict regional or international regulation of these products
can stifle innovation by encumbering new products with overburdening
requirements that restrict agility, requiring dozens of employees
instead of a handful for a startup. Such regulations might include
forcing geolocated application containers/servers to be hosted in
datacenters within the geographic borders of a nation or under
networks controlled by that nation. Examples include Brazil, which
recently forced Google to host Brazilian Gmail data in Brazil. Such
rules make sense at times, but may completely choke out
innovation. Also, such rules can make it difficult to index data
distributed across the world. Such problems with indexing or aggregate
data reduces the quality of targeted advertising products for
companies like Facebook or Google.


================================================================


(more about how we blind our own SIGINT via social media algorithms)

- how do they do it?
  - algorithms/etc (i already have this lined up)
    - overview, not too many specifics
  - where are the weak points?

#### Part Four: Combine parts 2 & 3 to Fight Censorship (title?)

- basically, take the emotion & motivations from part one
  - along with the philosophy of part two
  - and the technicals of part three
  - to lay out plans/ideas for preventing the free exchange of info
  - while retaining the safety of *some* limited discourse

- how can a completely decentralized system be constructed
  - why are shared incentives important?!
  - how can a system like that of 16th-19th century europe be
    constructed
  - special attention should be paid to how this system was
    architected *earlier* not later!
    - how the system functioned when it was less stable is more
      important to how the system retained that stability
      - in the 19th and 20th century, the academic system was well
        established.  how were these institutions architected before
        there was an economy/industry in place for them?
      - how/why did they function in absense of such an economy/industry?
        - why and HOW?
  - how can we carry that over to the 21st century?
    - how can we build robust safeguards in our institutions so they
      continue to function in absence of stability!
    - the urgency here is merited, as it only takes a generation or
      two for things to fall apart.


=============

#### reference [operational strategy]() article)

=============

describe how political movements can encourage its members to take
action online.
- some of those actions just help a movement grow.  that is, they
  aren't negative or divisive on their own. but in particular, a
  political/religious movement can encourage its members to take
  actions, the consequences of which they might not fully understand
  and the results of which, when combined with the feedback loops and
  vulnerabilities in machine learning algorithms cause significant
  harm to society.

- example: "birther" movement:
  - encouraged Barack Obama's most vocal (and perhaps more irrational)
    opposition to self-identify on social media.
    - well ... now you have a list of your most energetic opponents to
      harass IRL.
  - explain that our online words and actions have lasting effect that
    most of us don't understand.
    - younger people don't understand because they're young and don't
      understand the consequences
    - older people dont' understand because they're sometimes
      unfamiliar with technology and they don't understand it's
      capabilities

- explain how i "got lucky" fighting online censorship
  - i was very vocal before these web applications had the technical
    capacity for censorship and before our post-911 education system
    had engrained specific cultural "things" in our youth that
    encouraged them to avoid raising their voices.
    - there's something very, very different b/w people that graduated
      high school before 2006-ish and those that graduated
      afterwards. and particularly those who graduated after like
      2012ish.
      - the younger they are, the MORE AMORAL they are. i don't know
        if it's just confirmation bias from my personal perspective,
        but i have seen some of the worst of humanity hiding behind
        the smuggiest, overly-confident smirks.

facebook censorship:

unsubscribing has implicit negative feedback on newsfeed algorithms:
- not only do you hide that person from your view, but the lack of
  interaction encourages

- if people are encouraged to unsubscribe on a political basis
- that can create isolated communities of people
- and bc of the feedback effect from unsubscribing
  - this isolation is more pronounced
  - then there's another feedback effect where because social circle
    of people that are isolated online, then it narrows the set of
    information those people are exposed to
    - this, when combined with clustering algorithms that facebook
      would use to determine the "kinds" of people that are interested
      in various categories of things, then this would lead to
      significant distortion in what people see
    - so that leads to further effects
- most of this is made much worse by unsubscribing

it seems that every fresh channel that i use gets OK feedback,
sometimes they'll get an incredibly response
- then, every time after that, I get such a mediocre response

there's no real way to get around this censorship
- you can register accounts with new email addresses
  - but then your new accounts have no


The algorithms used for this are susceptible to passive and active
attacks/manipulation. When the NSA surveils, that's passive. If the
NSA were to subvert Facebook servers to alter Newsfeed rankings,
that's active. If DHS were to subtly encourage massive unsubscribes
from a person (somehow), that's passive because it's not coming from
within the Facebook application. Among other factors, when anyone
unsubscribes from you, this contributes to a feedback effect within
Facebook algorithms. This drives isolated subnetworks of users on
facebook, partially cut off from the Graph by political
differences. If anyone encourages systemic unsubscribes (E.G. for
political reasons!) then this contributes to those same feedback
effects that further !@#$ with the Facebook newsfeed algorithms!!!

I cannot emphasize this enough, but these could have MASSIVE
implications for the American economy, but it doesn't seem the left
really even gives a shit! And it really feels like censorship out
there!! Like political censorship. It's like we have our own Iron
Curtain over America, but it's more like a Silicon Blanket. And almost
all communication is via online interaction now. If you're censored
online, you're just wasting your time basically. If you were at a
party and everyone you talked to walked away from you, you'd probably
change your behavior, but with online interactions, YOU CAN'T SEE THAT
HAPPENING. So you continue wasting your time...

- mention shadowbanning (weaponized social media)
- how to determine whether or not you're being shadowbanned or
  your content is being shadowculled
  - to determine this, you have to know how this process works for
    both the corporations enabling this censorship and for shadowy
    government agencies participating in it.
  - there must be some "rules"
  - those rules are based on "costs"



- economic cost (the blowback of being caught on a massive scale)
  - for a second here, forget about the economic cost of snowden's
    revelations because those were mostly passive surveillance
    programs. but there was still a pretty large economic cost, wasn't
    there? people lost trust in these apps!
  - the corporations facilitating this, they don't want people to know
    it's happening

- intelligence cost
  - when people in various foreign countries post content to social
    media products, this produces content metrics.
    - this can be coupled with usage metrics to gauge how important
      that content was to the people who posted it and the people who
      interacted with it
  - so, when you're censoring or culling content on a political basis,
    guess what! you're losing the authenticity of those metrics, both
    content and usage. you're actually blinding yourself.
    - but there's a game theory element here. countries or groups can
      conduct informational warfare by altering the content format &
      metrics.
      - furthermore, they can simulate interactions to alter the usage
        metrics. this can mislead adversaries or algorithms.
      - for example, you can mistrain translation algorithms to make
        it harder for people to export your nation's content because
        it's more difficult to process your language.
    - this is all information warfare. write me a check please.

- however, this can distort the signals that we read from social media
  - that's true for both intelligence agencies and for businesses!
  - if we're muffling the response to some event, we can't
    authentically read the response to it.
    - what if we should know that if 10,000 people post about some
      event, this should indicate a possible terror threat, but no one
      is reading the analytics from that hashtag because it's being
      shadowbanned or shadowculled!
  - then you might say the right hand doesn't know what the left hand
    is doing!
    - if these tactics are being done in an organized manner, there
      won't be the "authentic" data and the "post-censored"
      data. there will just be the social media signals data as it
      appears. there are several reasons for this:
      - organizational and logistical reasons: if you're really
        censoring data, you don't want anyone to be able to question
        that, right?
      - reasons relating to engineering challenges: here, it's just
        not possible to have your cake and eat it too. we're lucky to
        be able to do half the stuff we can do with stream processing
        architectures.
      - introducing a censorship layer to this is incredibly
        complicated, but probably not impossible. the internet already
        appears to be a bit balkanized. yet, this is antithetical to
        these corporations mission statements and to their
        stockholder's bottom lines. you're just not going to be able
        to convince them to invest in this infrastructure without
        pointing guns to their backs! and if you do, you're still
        going to have HUMINT logistical challenges.

- what are the "rules" here? the people in charge of shadowbanning a
  hashtag, topic or domain have costs attributed to their actions
  - one of those costs is the cost of being caught culling someone's
    content
    - if someone is having their content, tweets or shares culled out,
      they're wasting their time, but if they know this or they find
      out, they're going to invest their energy elsewhere. thus,
      they'll escape the 'stasis' you've placed them in.
    - so that's one "cost". they don't want the person to find out
      because they'll react to it.
    - another cost to being caught here is that

- the technical "rules"
  - how does one cull content or links from a particular domain
  - it's a hard enough problem simply getting these web applications
    to work!
  - containerized web applications.
    - it's entirely possible to ... yada yada yada
      - requires HUMINT resources
  - layer 1,2,3,4,5 hacks
    - level3 and other internet backbone service providers
  - BGP hacks
    - silent IP rerouting
  - SSL hacks
    - when combined with ip rerouting
      - is basically, Konami's up-up, down-down, left-right,
        left-right, ...
    - if you have those SSL hacks, combined with BGP hacks (or any
      hack that lets you redirect specified traffic streams through
      servers/routers of your choosing) ...
      - you fucking win
    - and they do have all of this! several times over!!!!x!x!x!x!x!x!
    - however, there's a lot of moving parts here. and those moving
      parts lead to the potential for major bugs.
      - again, a great example of government interference in the free
        market leading to catastrophic problems! ... eventually
      - but government interference in this case leads to minor
        quality of service glitches.  just weird things that don't
        work right. unexplainable bugs, etc.
      - yet, when the full scope of this activity is known, it leads
        to a collapse in trust in US Technology products!! BECAUSE THE
        GOVERNMENT WOULDN"T GET THE FUCK OUT!

- the HUMINT "rules"
  - basically, you need to have people inside technology companies
    that you can leverage. preferably people closer to the top.
  - IMO, this is everywhere! as far as I can see, these people who can
    be leveraged, either directly or indirectly, are everywhere in the
    technology industry!

- so, how to fight back?



- a digital "bill of rights"
  - why? need to expand on these ideas before writing part 3

===========




exactly. also, your true value in social media comes from the unique
content you post/create. or at least, if you identify a story earlier
than others, that should be reflected in your reputation in the
newsfeed algorithms...

the dems are exploiting web applications and their algorithms to
project an intended appearance and to isolate/divide americans. these
algorithms already have their own weaknesses that encourage clusters
of users to become more clustered. they already have those weaknesses,
as they are. but these weaknesses can be abused to increase that
effect.

===========

because facebook and twitter newsfeed algorithms are perceived to be
"fair" the presentation of trends in social media is perceived to be
more authentic.
- i really don't believe that the average american understands how SEO
  and social media strategies work.
  - so unless the average american is leaping to conclusions as to how
    to control the presentation of information and trends on social
    media, then they are more likely to trust it more
    - it's a bit like the difference in publicity and advertising with
      regard to authenticity and trust
- if we were more aware of how to manipulate these things, then we'd
  be more cynical about what we see. it's easy to cause articles,
  topics and events to trend.
  - similarly, it's fairly simple to distract from an issue that just
    recently began trending online.
    - you basically try to trend other things and crowd it out
    - we are seeing so much of this happen!
  - this is all *passive* interference with technology and social
    media, by the way.
    - this is all possible without interfering with the operation of
      web applications!
      - if one was to actively interfere with web application, using
        the NSA for example, then it'd be fairly easy for technology
        companies to identify this behavior *and they would be
        pissed!*
    - doing this in almost any capacity is incredibly irresponsible
      and shows total disregard for the American economy!
      - it irreversibly damages the world's trust in American
        technology products, which is WHY I don't think it would
        happen.
      - if someone in power did this:
        - without taking the utmost care
        - or having the most dire need to do so
          - in no more than a handful of cases!
        - then that shows a reckless disregard for the American
          economy! this person or this group does not give a shit
          about America. At this point, technology, software and
          hardware are some of the few things that the American
          economy actually does have. And this is why I don't think
          it's going on, actually....
    - to make it clear, actively interfering with the operation of web
      applications is not the same thing as passive surveillance.  or
      even *passive* techniques to manipulate social media and/or SEO
      -- these imply utilizing the system in the same way as normal
      users would.
      - more active interference would require specific knowledge of a
        web application's design and codebase.  and I'm just going to
        leave it at that.

- how unsubscribes affect social media algorithms (outlined above)
  - a political movement could request that its supporters unsubscribe
    from users who post about specific topics. if they did so, this
    would cause a runaway effect that would lead to americans being
    isolated online and divided
    - they might not even be aware of the magnitude of effect that
      such a tactic would have! but it's pretty big.
      - social media newsfeed algorithms depend on getting signals
        that indicate how many people respond to your content
      - when your content receives little to no exposure, there's a
        feedback loop. reduced exposure leads to reduced likes,
        reduced likes and interaction leads to further reduced
        exposure.
        - when combined with clustering, categorization and
          recommendation algorithms, this leads to further isolation

  - when you're isolated online, you don't know that you're wasting
    your time! you might try to reach out to others, but you won't see
    why you're not getting through. it helps to have data and
    analytics. having access to google analytics helped me gamify the
    promotion of my blog and within a week or two, i instantly
    understood much of what I was doing wrong!
    - but i've been using facebook for years and I still have no idea
      why i can barely get a single person to like any of my posts.

- [like-farming and social-media tactics](http://www.foxnews.com/tech/2016/02/27/dont-click-like-on-facebook-again-until-read-this.html)

and so, how do the social media & SEO censorship/distraction tactics
above affect the model of censorship outlined above.
- consider a graph with a temporal component that can be grouped to
  show the set of topics an individual or groupings of individuals
  have seen.
  - you can consider or understand everything someone saw today or last week or
    last month.
    - and you can do the same for groups of individuals
- social media censorship/distraction limits the ideas that people are
  exposed to
  - in the same way that cultures can blacklist or whitelist ideas or
    topics, these tactics do the same in a way that limits that graph
    - you can particularly effect the range of ideas that someone is
      exposed to
      - again, another feedback loop with newsfeed algorithms. by
        eliminating some topics or distracting from them, this shifts
        the discussion elsewhere. people talk about other topics and
        those are given much greater exposure.

- newsfeed algorithms should almost incorporate their antithesis
  - instead of focusing on what drives activity, they should also
    cause other topics to be featured, just to avoid the potential for
    feedback loops.
    - unsubscribes should have a timeout or something.  if you don't
      want to see what someone posts, at least send the clear
      indication to that person. just drop them from your friends
      list. unsubscribes are just one more passive aggressive
      interaction in our society. there are far too many avenues for
      passive aggressive behavior with social media.
  - these problems are difficult for developers and data scientists to
    observe and measure, so the people designing these things aren't
    necessarily at fault.
    - there are so many feedback loops in the newsfeed
      algorithms. that's really where the problems are. i don't have
      access to any of this data and I don't have much machine
      learning experience, beyond a few courses, but I can see the
      effect that manipulating these algorithms have.  I feel isolated
      in real life and online and I struggle to understand why.
  - furthermore, there are economic pressures which motivate SEO &
    Social Media companies to circumvent measures taken by newsfeed
    algorithms to promote fairness. they are encouraged to manipulate
    these algorithms for their benefit.

-
  [shadowbanning](http://newstarget.com/2016-07-29-bypass-twitter-censorship-by-using-alternative-information-sources-fetch-news-and-goodgopher-com.html)
  - so apparently, those in charge of censorship don't actually care.
